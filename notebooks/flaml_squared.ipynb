{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34f30c6",
   "metadata": {},
   "source": [
    "## FLAML for hp optimisation and model selection\n",
    "We use FLAML twice, first to find the best component model for each estimator, and then to optimise the estimators themselves and choose the best estimator. Here we show how it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7480f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now.. \n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "data_dir = os.path.realpath(os.path.join(root_path, \"auto-causality/data\"))\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "sys.path.append(os.path.join(root_path, \"dowhy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8de5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_causality.utils import featurize\n",
    "from auto_causality import AutoCausality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c777cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all the control parameters here\n",
    "train_size = 0.5\n",
    "test_size = None\n",
    "time_budget = 300\n",
    "num_cores = os.cpu_count() - 1\n",
    "conf_intervals = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9331f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load raw data\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\",\n",
    "    header=None,\n",
    ")\n",
    "col = [\n",
    "    \"treatment\",\n",
    "    \"y_factual\",\n",
    "    \"y_cfactual\",\n",
    "    \"mu0\",\n",
    "    \"mu1\",\n",
    "]\n",
    "for i in range(1, 26):\n",
    "    col.append(\"x\" + str(i))\n",
    "data.columns = col\n",
    "# drop the columns we don't care about\n",
    "ignore_patterns = [\"y_cfactual\", \"mu\"]\n",
    "ignore_cols = [c for c in data.columns if any([s in c for s in ignore_patterns])]\n",
    "data = data.drop(columns=ignore_cols)\n",
    "\n",
    "\n",
    "# prepare the data\n",
    "\n",
    "treatment = \"treatment\"\n",
    "targets = [\"y_factual\"]  # it's good to allow multiple ones\n",
    "features = [c for c in data.columns if c not in [treatment] + targets]\n",
    "\n",
    "data[treatment] = data[treatment].astype(int)\n",
    "# this is a trick to bypass some DoWhy/EconML bugs\n",
    "data[\"random\"] = np.random.randint(0, 2, size=len(data))\n",
    "\n",
    "used_df = featurize(\n",
    "    data, features=features, exclude_cols=[treatment] + targets, drop_first=False,\n",
    ")\n",
    "used_features = [\n",
    "    c for c in used_df.columns if c not in ignore_cols + [treatment] + targets\n",
    "]\n",
    "\n",
    "\n",
    "# Let's treat all features as effect modifiers\n",
    "features_X = [f for f in used_features if f != \"random\"]\n",
    "features_W = [f for f in used_features if f not in features_X]\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(used_df, train_size=train_size)\n",
    "if test_size is not None:\n",
    "    test_df = test_df.sample(test_size)\n",
    "\n",
    "test_df.to_csv(os.path.join(data_dir, f\"test_{time_budget}.csv\"))\n",
    "train_df.to_csv(os.path.join(data_dir, f\"train_{time_budget}.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d234a",
   "metadata": {},
   "source": [
    "### Model fitting & scoring\n",
    "Here we fit a (selection of) model(s) to the data and score them with the ERUPT metric on held-out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68c4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 03-01 23:58:28] {326} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 03-01 23:58:28] {447} INFO - trial 1 config: {'fit_cate_intercept': 1, 'mc_iters': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting estimators: ['backdoor.econml.dml.LinearDML', 'backdoor.econml.dml.SparseLinearDML', 'backdoor.econml.dml.CausalForestDML', 'backdoor.econml.dr.ForestDRLearner']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sabs-r3/Documents/auto-causality/notebooks/flaml_squared.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sabs-r3/Documents/auto-causality/notebooks/flaml_squared.ipynb#ch0000006?line=1'>2</a>\u001b[0m outcome \u001b[39m=\u001b[39m targets[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sabs-r3/Documents/auto-causality/notebooks/flaml_squared.ipynb#ch0000006?line=2'>3</a>\u001b[0m auto_causality \u001b[39m=\u001b[39m AutoCausality(time_budget\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,components_time_budget\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,estimator_list\u001b[39m=\u001b[39mestimator_list)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sabs-r3/Documents/auto-causality/notebooks/flaml_squared.ipynb#ch0000006?line=4'>5</a>\u001b[0m myresults \u001b[39m=\u001b[39m auto_causality\u001b[39m.\u001b[39;49mfit(train_df, test_df, treatment, outcome,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sabs-r3/Documents/auto-causality/notebooks/flaml_squared.ipynb#ch0000006?line=5'>6</a>\u001b[0m  features_W, features_X, \u001b[39m'\u001b[39;49m\u001b[39mqini\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sabs-r3/Documents/auto-causality/notebooks/flaml_squared.ipynb#ch0000006?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest estimator: \u001b[39m\u001b[39m{\u001b[39;00mauto_causality\u001b[39m.\u001b[39mbest_estimator\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/auto-causality/auto_causality/optimiser.py:250\u001b[0m, in \u001b[0;36mAutoCausality.fit\u001b[0;34m(self, train_df, test_df, treatment, outcome, common_causes, effect_modifiers, metric)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=244'>245</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=245'>246</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator] \u001b[39m=\u001b[39m best_trial\u001b[39m.\u001b[39mlast_result[\n\u001b[1;32m    <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=246'>247</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings[\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=247'>248</a>\u001b[0m         ]\n\u001b[1;32m    <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=248'>249</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m--> <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=249'>250</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m... Estimator: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings[\u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator]\u001b[39m:\u001b[39;00m\u001b[39m6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/Documents/auto-causality/auto_causality/optimiser.py?line=250'>251</a>\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator_list = [\"dml\",\"ForestDR\"]\n",
    "outcome = targets[0]\n",
    "auto_causality = AutoCausality(time_budget=100,components_time_budget=100,estimator_list=estimator_list)\n",
    "\n",
    "myresults = auto_causality.fit(train_df, test_df, treatment, outcome,\n",
    " features_W, features_X, 'qini')\n",
    "\n",
    "print(f\"Best estimator: {auto_causality.best_estimator}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3323bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4693b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
