{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34f30c6",
   "metadata": {},
   "source": [
    "## FLAML for hp optimisation and model selection\n",
    "We use FLAML twice, first to find the best component model for each estimator, and then to optimise the estimators themselves and choose the best estimator. Here we show how it's done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7480f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now.. \n",
    "\n",
    "# the below checks for whether we run dowhy and auto-causality from source\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try: \n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "    \n",
    "try:\n",
    "    import dowhy\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"dowhy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8de5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_causality import AutoCausality\n",
    "from auto_causality.datasets import synth_ihdp, preprocess_dataset\n",
    "from auto_causality.scoring import ate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d234a",
   "metadata": {},
   "source": [
    "### Model fitting & scoring\n",
    "Here we fit a (selection of) model(s) to the data and score them with the ERUPT metric on held-out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68c4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 03-15 17:47:50] {2211} WARNING - Time taken to find the best model is 94% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.automl: 03-15 17:47:52] {2211} WARNING - Time taken to find the best model is 82% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.tune.tune: 03-15 17:47:58] {326} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 03-15 17:47:58] {447} INFO - trial 1 config: {'fit_cate_intercept': 1, 'mc_iters': 0}\n",
      "[flaml.tune.tune: 03-15 17:48:02] {108} INFO - result: {'erupt': 6.32789671421051, 'qini': -0.016454312144289912, 'auc': 0.5271073490579692, 'ate': 3.789311297861625, 'r_score': -0.02264565589557921, 'estimator': <dowhy.causal_estimator.CausalEstimate object at 0x0000026A41B0B880>, 'scores': {'estimator_name': 'backdoor.econml.dml.LinearDML', 'train': {'erupt': 6.454533366022752, 'qini': 0.033705648485451385, 'auc': 0.5422723983356651, 'r_score': 0.0493278383914737, 'ate': 3.8136580757045535, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A41F76160>, 'values':      treated  y_factual         p  policy   weights\n",
      "0        0.0   2.847216  0.177554    True  5.575301\n",
      "1        0.0   3.372611  0.177554    True       NaN\n",
      "2        0.0   1.395117  0.177554    True  0.000000\n",
      "3        1.0   6.871173  0.177554    True  0.000000\n",
      "4        0.0   0.785504  0.177554    True  0.000000\n",
      "..       ...        ...       ...     ...       ...\n",
      "592      1.0   6.947153  0.177554    True  5.575301\n",
      "593      0.0   1.158305  0.177554    True  0.000000\n",
      "594      0.0   1.435092  0.177554    True  1.203629\n",
      "595      0.0   6.932994  0.177554   False       NaN\n",
      "596      0.0   2.440818  0.177554    True       NaN\n",
      "\n",
      "[597 rows x 5 columns]}, 'validation': {'erupt': 6.32789671421051, 'qini': -0.016454312144289912, 'auc': 0.5271073490579692, 'r_score': -0.02264565589557921, 'ate': 3.789311297861625, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A41F76C40>, 'values':      treated  y_factual     p  policy  weights\n",
      "0        0.0   5.209862  0.22    True      NaN\n",
      "1        0.0   2.128057  0.22    True      0.0\n",
      "2        0.0   0.084559  0.22    True      NaN\n",
      "3        1.0   5.501678  0.22    True      NaN\n",
      "4        1.0   5.926609  0.22    True      NaN\n",
      "..       ...        ...   ...     ...      ...\n",
      "145      0.0   2.821132  0.22    True      NaN\n",
      "146      0.0   6.911762  0.22    True      NaN\n",
      "147      0.0   2.747685  0.22    True      NaN\n",
      "148      0.0   0.351428  0.22    True      NaN\n",
      "149      1.0   6.461460  0.22    True      0.0\n",
      "\n",
      "[150 rows x 5 columns]}, 'test': {'erupt': 6.6164964516957605, 'qini': -0.06795254974986786, 'auc': 0.48722790303153274, 'r_score': -0.025592326811895605, 'ate': 3.9475854547101306, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A41F76A00>, 'values':      treated  y_factual    p  policy  weights\n",
      "0        0.0   0.906938  0.2    True      NaN\n",
      "1        0.0   0.750300  0.2    True      NaN\n",
      "2        1.0   7.834469  0.2    True      0.0\n",
      "3        1.0   8.182734  0.2    True      NaN\n",
      "4        0.0   4.230410  0.2    True      0.0\n",
      "..       ...        ...  ...     ...      ...\n",
      "145      0.0   2.011224  0.2    True      NaN\n",
      "146      0.0   1.042562  0.2    True      NaN\n",
      "147      0.0   0.613519  0.2    True      NaN\n",
      "148      0.0   0.627056  0.2    True      NaN\n",
      "149      1.0   4.748230  0.2    True      NaN\n",
      "\n",
      "[150 rows x 5 columns]}}, 'training_iteration': 0, 'config': {'fit_cate_intercept': 1, 'mc_iters': 0}, 'config/fit_cate_intercept': 1, 'config/mc_iters': 0, 'experiment_tag': 'exp', 'time_total_s': 4.3968284130096436}\n",
      "[flaml.tune.tune: 03-15 17:48:02] {326} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 03-15 17:48:02] {447} INFO - trial 1 config: {'fit_cate_intercept': 1, 'mc_iters': 0, 'n_alphas': 87, 'n_alphas_cov': 5, 'tol': 3.81e-05, 'max_iter': 18500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Estimator: backdoor.econml.dml.LinearDML\n",
      " erupt (validation): 6.327897\n",
      " erupt (test): 6.616496\n",
      " qini (validation): -0.016454\n",
      " qini (test): -0.067953\n",
      " auc (validation): 0.527107\n",
      " auc (test): 0.487228\n",
      " ate (validation): 3.789311\n",
      " ate (test): 3.947585\n",
      " r_score (validation): -0.022646\n",
      " r_score (test): -0.025592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 03-15 17:48:11] {108} INFO - result: {'erupt': 6.326161731373182, 'qini': 0.003207553759510602, 'auc': 0.5391303829066524, 'ate': 3.8749767562974338, 'r_score': 0.006958191290367566, 'estimator': <dowhy.causal_estimator.CausalEstimate object at 0x0000026A41E35670>, 'scores': {'estimator_name': 'backdoor.econml.dml.SparseLinearDML', 'train': {'erupt': 6.4649506977711155, 'qini': 0.060994886864560546, 'auc': 0.5449125990642756, 'r_score': 0.03332082210973497, 'ate': 3.991167940353232, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A41C764C0>, 'values':      treated  y_factual         p  policy   weights\n",
      "0        0.0   2.847216  0.177554    True  5.620628\n",
      "1        0.0   3.372611  0.177554    True       NaN\n",
      "2        0.0   1.395117  0.177554    True  0.000000\n",
      "3        1.0   6.871173  0.177554    True  0.000000\n",
      "4        0.0   0.785504  0.177554    True  0.000000\n",
      "..       ...        ...       ...     ...       ...\n",
      "592      1.0   6.947153  0.177554    True  5.620628\n",
      "593      0.0   1.158305  0.177554    True  0.000000\n",
      "594      0.0   1.435092  0.177554    True  0.000000\n",
      "595      0.0   6.932994  0.177554    True       NaN\n",
      "596      0.0   2.440818  0.177554    True       NaN\n",
      "\n",
      "[597 rows x 5 columns]}, 'validation': {'erupt': 6.326161731373182, 'qini': 0.003207553759510602, 'auc': 0.5391303829066524, 'r_score': 0.006958191290367566, 'ate': 3.8749767562974338, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A43999400>, 'values':      treated  y_factual     p  policy  weights\n",
      "0        0.0   5.209862  0.22    True      NaN\n",
      "1        0.0   2.128057  0.22    True      0.0\n",
      "2        0.0   0.084559  0.22    True      NaN\n",
      "3        1.0   5.501678  0.22    True      NaN\n",
      "4        1.0   5.926609  0.22    True      NaN\n",
      "..       ...        ...   ...     ...      ...\n",
      "145      0.0   2.821132  0.22    True      NaN\n",
      "146      0.0   6.911762  0.22    True      NaN\n",
      "147      0.0   2.747685  0.22    True      NaN\n",
      "148      0.0   0.351428  0.22    True      NaN\n",
      "149      1.0   6.461460  0.22    True      0.0\n",
      "\n",
      "[150 rows x 5 columns]}, 'test': {'erupt': 6.6164964516957605, 'qini': -0.08149533405436553, 'auc': 0.48529229345873665, 'r_score': -0.016832986630990865, 'ate': 4.078688322261651, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A43999FD0>, 'values':      treated  y_factual    p  policy  weights\n",
      "0        0.0   0.906938  0.2    True      NaN\n",
      "1        0.0   0.750300  0.2    True      NaN\n",
      "2        1.0   7.834469  0.2    True      0.0\n",
      "3        1.0   8.182734  0.2    True      NaN\n",
      "4        0.0   4.230410  0.2    True      0.0\n",
      "..       ...        ...  ...     ...      ...\n",
      "145      0.0   2.011224  0.2    True      NaN\n",
      "146      0.0   1.042562  0.2    True      NaN\n",
      "147      0.0   0.613519  0.2    True      NaN\n",
      "148      0.0   0.627056  0.2    True      NaN\n",
      "149      1.0   4.748230  0.2    True      NaN\n",
      "\n",
      "[150 rows x 5 columns]}}, 'training_iteration': 0, 'config': {'fit_cate_intercept': 1, 'mc_iters': 0, 'n_alphas': 87, 'n_alphas_cov': 5, 'tol': 3.81e-05, 'max_iter': 18500}, 'config/fit_cate_intercept': 1, 'config/mc_iters': 0, 'config/n_alphas': 87, 'config/n_alphas_cov': 5, 'config/tol': 3.81e-05, 'config/max_iter': 18500, 'experiment_tag': 'exp', 'time_total_s': 8.637248992919922}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Estimator: backdoor.econml.dml.SparseLinearDML\n",
      " erupt (validation): 6.326162\n",
      " erupt (test): 6.616496\n",
      " qini (validation): 0.003208\n",
      " qini (test): -0.081495\n",
      " auc (validation): 0.539130\n",
      " auc (test): 0.485292\n",
      " ate (validation): 3.874977\n",
      " ate (test): 4.078688\n",
      " r_score (validation): 0.006958\n",
      " r_score (test): -0.016833\n",
      "config: {'overall_model': AutoML(append_log=False, auto_augment=True, early_stop=False, ensemble=False,\n",
      "       estimator_list='auto', eval_method='auto', hpo_method='auto',\n",
      "       keep_search_state=False, learner_selector='sample', log_file_name='',\n",
      "       log_training_metric=False, log_type='better', max_iter=1000000,\n",
      "       mem_thres=4294967296, metric='auto', min_sample_size=10000,\n",
      "       model_history=False, n_concurrent_trials=1, n_jobs=-1, n_splits=5,\n",
      "       pred_time_limit=1e-05, retrain_full=True, sample=True, split_ratio=0.1,\n",
      "       split_type='auto', starting_points={}, task='regression', time_budget=2,\n",
      "       train_time_limit=inf, use_ray=False, ...)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 03-15 17:48:13] {2211} WARNING - Time taken to find the best model is 96% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.tune.tune: 03-15 17:48:13] {326} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 03-15 17:48:13] {447} INFO - trial 1 config: {'min_propensity': 3.070155442191211e-06, 'mc_iters': 1, 'n_estimators': 324, 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 7, 'min_weight_fraction_leaf': 0.377743449018298, 'max_features': 'sqrt', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.378105341302808, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Estimator: backdoor.econml.metalearners.SLearner\n",
      " erupt (validation): 6.368044\n",
      " erupt (test): 6.620952\n",
      " qini (validation): 0.023626\n",
      " qini (test): -0.072504\n",
      " auc (validation): 0.576055\n",
      " auc (test): 0.541810\n",
      " ate (validation): 3.960894\n",
      " ate (test): 4.018638\n",
      " r_score (validation): 0.081523\n",
      " r_score (test): 0.048389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 03-15 17:48:18] {108} INFO - result: {'erupt': 6.326161731373182, 'qini': -0.09313027300538203, 'auc': 0.4618810041675895, 'ate': 4.073847574256198, 'r_score': -0.030115627581726256, 'estimator': <dowhy.causal_estimator.CausalEstimate object at 0x0000026A45403FD0>, 'scores': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'train': {'erupt': 6.465497504990055, 'qini': -0.0028583504389217084, 'auc': 0.501461675769016, 'r_score': -0.005822761034007362, 'ate': 4.073847574256195, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A450422B0>, 'values':      treated  y_factual         p  policy   weights\n",
      "0        0.0   2.847216  0.177554    True  5.632075\n",
      "1        0.0   3.372611  0.177554    True       NaN\n",
      "2        0.0   1.395117  0.177554    True  0.000000\n",
      "3        1.0   6.871173  0.177554    True  0.000000\n",
      "4        0.0   0.785504  0.177554    True  0.000000\n",
      "..       ...        ...       ...     ...       ...\n",
      "592      1.0   6.947153  0.177554    True  5.632075\n",
      "593      0.0   1.158305  0.177554    True  0.000000\n",
      "594      0.0   1.435092  0.177554    True  0.000000\n",
      "595      0.0   6.932994  0.177554    True       NaN\n",
      "596      0.0   2.440818  0.177554    True       NaN\n",
      "\n",
      "[597 rows x 5 columns]}, 'validation': {'erupt': 6.326161731373182, 'qini': -0.09313027300538203, 'auc': 0.4618810041675895, 'r_score': -0.030115627581726256, 'ate': 4.073847574256198, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A45042910>, 'values':      treated  y_factual     p  policy  weights\n",
      "0        0.0   5.209862  0.22    True      NaN\n",
      "1        0.0   2.128057  0.22    True      0.0\n",
      "2        0.0   0.084559  0.22    True      NaN\n",
      "3        1.0   5.501678  0.22    True      NaN\n",
      "4        1.0   5.926609  0.22    True      NaN\n",
      "..       ...        ...   ...     ...      ...\n",
      "145      0.0   2.821132  0.22    True      NaN\n",
      "146      0.0   6.911762  0.22    True      NaN\n",
      "147      0.0   2.747685  0.22    True      NaN\n",
      "148      0.0   0.351428  0.22    True      NaN\n",
      "149      1.0   6.461460  0.22    True      0.0\n",
      "\n",
      "[150 rows x 5 columns]}, 'test': {'erupt': 6.6164964516957605, 'qini': -0.009460841327540834, 'auc': 0.4942631286296482, 'r_score': -0.006539965567361694, 'ate': 4.073847574256197, 'intrp': <econml.cate_interpreter._interpreters.SingleTreeCateInterpreter object at 0x0000026A45042DC0>, 'values':      treated  y_factual    p  policy  weights\n",
      "0        0.0   0.906938  0.2    True      NaN\n",
      "1        0.0   0.750300  0.2    True      NaN\n",
      "2        1.0   7.834469  0.2    True      0.0\n",
      "3        1.0   8.182734  0.2    True      NaN\n",
      "4        0.0   4.230410  0.2    True      0.0\n",
      "..       ...        ...  ...     ...      ...\n",
      "145      0.0   2.011224  0.2    True      NaN\n",
      "146      0.0   1.042562  0.2    True      NaN\n",
      "147      0.0   0.613519  0.2    True      NaN\n",
      "148      0.0   0.627056  0.2    True      NaN\n",
      "149      1.0   4.748230  0.2    True      NaN\n",
      "\n",
      "[150 rows x 5 columns]}}, 'training_iteration': 0, 'config': {'min_propensity': 3.070155442191211e-06, 'mc_iters': 1, 'n_estimators': 324, 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 7, 'min_weight_fraction_leaf': 0.377743449018298, 'max_features': 'sqrt', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.378105341302808, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 7}, 'config/min_propensity': 3.070155442191211e-06, 'config/mc_iters': 1, 'config/n_estimators': 324, 'config/max_depth': 2, 'config/min_samples_split': 18, 'config/min_samples_leaf': 7, 'config/min_weight_fraction_leaf': 0.377743449018298, 'config/max_features': 'sqrt', 'config/min_impurity_decrease': 2.6639242043080236, 'config/max_samples': 0.378105341302808, 'config/min_balancedness_tol': 0.006805783323944936, 'config/honest': 1, 'config/subforest_size': 7, 'experiment_tag': 'exp', 'time_total_s': 4.952738046646118}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Estimator: backdoor.econml.dr.ForestDRLearner\n",
      " erupt (validation): 6.326162\n",
      " erupt (test): 6.616496\n",
      " qini (validation): -0.093130\n",
      " qini (test): -0.009461\n",
      " auc (validation): 0.461881\n",
      " auc (test): 0.494263\n",
      " ate (validation): 4.073848\n",
      " ate (test): 4.073848\n",
      " r_score (validation): -0.030116\n",
      " r_score (test): -0.006540\n",
      "Best estimator: backdoor.econml.metalearners.SLearner\n",
      "best config: {}\n",
      "best score: 6.368043645320948\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "data_df = synth_ihdp()\n",
    "data_df, features_X, features_W, targets, treatment = preprocess_dataset(data_df)\n",
    "outcome = targets[0]\n",
    "\n",
    "# choose which estimators to fit\n",
    "estimator_list = [\"LinearDML\",\"SLearner\", \"ForestDRLearner\"] #\"TransformedOutcome\" doesn't work?\n",
    "\n",
    "# init autocausality object with chosen metric to optimise\n",
    "ac = AutoCausality(\n",
    "    time_budget=3, \n",
    "    estimator_list=estimator_list, \n",
    "    metric=\"erupt\",\n",
    "    verbose=3,\n",
    "    components_verbose=2,\n",
    "    components_time_budget=30,\n",
    "    use_ray=False\n",
    ")\n",
    "\n",
    "# run autocausality\n",
    "myresults = ac.fit(data_df, treatment, outcome, features_W, features_X)\n",
    "\n",
    "# return best estimator\n",
    "print(f\"Best estimator: {ac.best_estimator}\")\n",
    "# config of best estimator:\n",
    "print(f\"best config: {ac.best_config}\")\n",
    "# best score:\n",
    "print(f\"best score: {ac.best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = targets[0]\n",
    "ac.full_scores[\"baseline\"]={\"estimator\": \"baseline\",\n",
    "                               \"outcome\": outcome,\n",
    "                              \"train\":{\"erupt\": ac.train_df[outcome].mean(),\n",
    "                                       \"ate\": ate(ac.train_df[treatment],ac.train_df[outcome])[0]},\n",
    "                              \"validation\":{\"erupt\": ac.test_df[outcome].mean(),\n",
    "                                      \"ate\": ate(ac.test_df[treatment],ac.test_df[outcome])[0]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "colors = ([matplotlib.colors.CSS4_COLORS['black']] +\n",
    "    list(matplotlib.colors.TABLEAU_COLORS) + [\n",
    "    matplotlib.colors.CSS4_COLORS['lime'],\n",
    "    matplotlib.colors.CSS4_COLORS['yellow'],\n",
    "    matplotlib.colors.CSS4_COLORS['pink']\n",
    "])\n",
    "\n",
    "v = ac.full_scores\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.title(outcome)\n",
    "for (est, scr),col in zip(v.items(),colors):\n",
    "    sc = [scr['train']['erupt'], scr['validation']['erupt']]\n",
    "    crv = [scr['train']['ate'], scr['validation']['ate']]\n",
    "    plt.plot(sc, crv, color=col, marker=\"o\")\n",
    "    plt.scatter(sc[1:],crv[1:], c=col, s=120 )\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"ERUPT score\")\n",
    "    plt.ylabel(\"ATE\")\n",
    "    plt.legend(v.keys(),bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr = ac.full_scores[ac.best_estimator]\n",
    "intrp = scr['validation']['intrp']\n",
    "plt.figure(figsize=(15, 7))\n",
    "try: \n",
    "    feature_names = intrp.feature_names\n",
    "except:\n",
    "    feature_names = features_X + [ w for w in features_W if w not in features_X]\n",
    "intrp.plot(feature_names=intrp.feature_names, fontsize=10)\n",
    "#         intrp.plot( fontsize=10)\n",
    "plt.title(f\"{ac.best_estimator}_{outcome}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d544dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add SHAP plots!\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# and now let's visualize feature importances!\n",
    "from auto_causality.shap import shap_values\n",
    "\n",
    "# Shapley values calculation can be slow so let's subsample\n",
    "this_df = ac.test_df.sample(100)\n",
    "\n",
    "wanted = [\"CausalForestDML\"]#,\"ForestDRLearner\",\"DirectUpliftDoWhyWrapper\"]#,\"CausalForestDML\",]\n",
    "\n",
    "scr = ac.full_scores[ac.best_estimator]\n",
    "print(outcome, ac.best_estimator)\n",
    "est = ac.estimates[ac.best_estimator]\n",
    "shaps = shap_values(est, this_df)\n",
    "\n",
    "plt.title(outcome + '_' + ac.best_estimator.split('.')[-1])\n",
    "shap.summary_plot(shaps, this_df[est.estimator._effect_modifier_names])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
